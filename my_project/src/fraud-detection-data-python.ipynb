{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9370092-2caf-4fdc-8005-96ae91909c93",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# try:\n",
    "#     import dlt\n",
    "# except ImportError:\n",
    "#     class dlt:\n",
    "#         def table(comment, **options):\n",
    "#             def _(f):\n",
    "#                 pass\n",
    "#             return _\n",
    "\n",
    "# import os\n",
    "# from pyspark.sql import SparkSession\n",
    "# from pyspark.sql.types import StructType, StructField, TimestampType, IntegerType, DoubleType, StringType, BooleanType, ArrayType, LongType, MapType\n",
    "# from pyspark.sql.functions import from_json, col, size, explode, json_tuple, get_json_object, from_unixtime\n",
    "# from pyspark.sql.types import TimestampType, DateType\n",
    "# import dlt\n",
    "# from pyspark.sql import functions as F\n",
    "\n",
    "# # Define schema for the incoming JSON data\n",
    "# base_schema = StructType([\n",
    "#     StructField(\"TransactionID\", StringType(), True),\n",
    "#     StructField(\"UserID\", StringType(), True),\n",
    "#     StructField(\"TransactionDate\", TimestampType(), True),\n",
    "#     StructField(\"TransactionAmount\", DoubleType(), True),\n",
    "#     StructField(\"TransactionType\", StringType(), True),\n",
    "#     StructField(\"MerchantID\", StringType(), True),\n",
    "#     StructField(\"Currency\", StringType(), True),\n",
    "#     StructField(\"TransactionStatus\", StringType(), True),\n",
    "#     StructField(\"DeviceType\", StringType(), True),\n",
    "#     StructField(\"IP_Address\", StringType(), True),\n",
    "#     StructField(\"PaymentMethod\", StringType(), True),\n",
    "#     StructField(\"SuspiciousFlag\", BooleanType(), True),\n",
    "#     StructField(\"IsFraud\", BooleanType(), True),\n",
    "#     StructField(\"AnomalyScore\", DoubleType(), True),\n",
    "#     StructField(\"Age\", IntegerType(), True),\n",
    "#     StructField(\"Gender\", StringType(), True),\n",
    "#     StructField(\"AccountCreationDate\", TimestampType(), True),\n",
    "#     StructField(\"Location\", StringType(), True),\n",
    "#     StructField(\"LocationCoordinates\", StringType(), True),\n",
    "#     StructField(\"AccountStatus\", StringType(), True),\n",
    "#     StructField(\"DeviceID\", StringType(), True),\n",
    "#     StructField(\"UserProfileCompleteness\", DoubleType(), True),\n",
    "#     StructField(\"PreviousFraudAttempts\", IntegerType(), True)\n",
    "# ])\n",
    "\n",
    "# # Create or refresh the raw (bronze) table\n",
    "# @dlt.table(\n",
    "#     comment=\"Bronze table for raw fraud detection data\",\n",
    "#     table_properties={\n",
    "#         \"quality\": \"bronze\"\n",
    "#     }\n",
    "# )\n",
    "# def br_fraud_detection_raw_data_historical():\n",
    "#     raw_data = spark.readStream \\\n",
    "#         .format(\"cloudFiles\") \\\n",
    "#         .option(\"cloudFiles.format\", \"json\") \\\n",
    "#         .option(\"cloudFiles.inferColumnTypes\", \"true\") \\\n",
    "#         .option(\"cloudFiles.rescuedDataColumn\", \"rescue_col\") \\\n",
    "#         .load(\"s3://fraud-detection-raw-data1/year=*/transactions_*.json\")\n",
    "    \n",
    "#     return raw_data\n",
    "\n",
    "# # Create or refresh the fact table (silver quality)\n",
    "# @dlt.table(\n",
    "#     comment=\"Silver table for fraud detection transactions\",\n",
    "#     table_properties={\n",
    "#         \"quality\": \"silver\"\n",
    "#     }\n",
    "# )\n",
    "# def si_transactions_fact():\n",
    "#     raw_data = dlt.read_stream(\"br_fraud_detection_raw_data_historical\")\n",
    "    \n",
    "#     # Selecting distinct columns to create the fact table\n",
    "#     return raw_data.select(\n",
    "#         \"TransactionID\",\n",
    "#         \"UserID\",\n",
    "#         \"TransactionDate\",\n",
    "#         \"TransactionAmount\",\n",
    "#         \"TransactionType\",\n",
    "#         \"MerchantID\",\n",
    "#         \"Currency\",\n",
    "#         \"TransactionStatus\",\n",
    "#         \"DeviceType\",\n",
    "#         \"IP_Address\",\n",
    "#         \"PaymentMethod\",\n",
    "#         \"SuspiciousFlag\",\n",
    "#         \"IsFraud\",\n",
    "#         \"AnomalyScore\",\n",
    "#         \"Age\",\n",
    "#         \"Gender\",\n",
    "#         \"AccountCreationDate\",\n",
    "#         \"Location\",\n",
    "#         \"LocationCoordinates\",\n",
    "#         \"AccountStatus\",\n",
    "#         \"DeviceID\",\n",
    "#         \"UserProfileCompleteness\",\n",
    "#         \"PreviousFraudAttempts\"\n",
    "#     ).distinct()\n",
    "\n",
    "\n",
    "\n",
    "# # import dlt\n",
    "# # from pyspark.sql.functions import first, when\n",
    "\n",
    "# # @dlt.table(name=\"si_merchants_dimension\", comment=\"Silver quality Merchants Dimension table\", table_properties={\"quality\": \"silver\"})\n",
    "# # def si_merchants_dimension():\n",
    "# #     raw_data = dlt.read(\"br_fraud_detection_raw_data_historical\")\n",
    "# #     return raw_data.groupBy(\"MerchantID\").agg(\n",
    "# #         F.first(\"LocationCoordinates\").alias(\"MerchantLocation\"),\n",
    "# #         # Replace 'N/A' with the actual column name or use a default value\n",
    "# #         F.first(F.when(F.col(\"ContactColumnName\").isNotNull(), F.col(\"ContactColumnName\")).otherwise(\"Unknown\")).alias(\"MerchantContact\"),  # Replace 'ContactColumnName' with the actual column name\n",
    "# #         F.first(\"Active\").alias(\"MerchantStatus\"),\n",
    "# #         F.when(raw_data.MerchantID.isin(\"Amazon\", \"eBay\", \"Best Buy\"), \"Electronics\")\n",
    "# #             .when(raw_data.MerchantID.isin(\"Walmart\", \"Target\"), \"Groceries\")\n",
    "# #             .otherwise(\"Other\").alias(\"MerchantCategory\")\n",
    "# #     )\n",
    "\n",
    "# from pyspark.sql.functions import first\n",
    "\n",
    "# @dlt.table(name=\"si_users_dimension\", comment=\"Silver quality Users Dimension table\", table_properties={\"quality\": \"silver\"})\n",
    "# def si_users_dimension():\n",
    "#     raw_data = dlt.read(\"br_fraud_detection_raw_data_historical\")\n",
    "#     return raw_data.groupBy(\"UserID\").agg(\n",
    "#         first(\"Age\").alias(\"Age\"),\n",
    "#         first(\"Gender\").alias(\"Gender\"),\n",
    "#         first(\"AccountCreationDate\").alias(\"AccountCreationDate\"),\n",
    "#         first(\"AccountStatus\").alias(\"AccountStatus\"),\n",
    "#         first(\"UserProfileCompleteness\").alias(\"UserProfileCompleteness\"),\n",
    "#         first(\"PreviousFraudAttempts\").alias(\"PreviousFraudAttempts\"),\n",
    "#         first(\"Location\").alias(\"UserLocation\")\n",
    "#     )\n",
    "\n",
    "\n",
    "# @dlt.table(name=\"si_devices_dimension\", comment=\"Silver quality Devices Dimension table\", table_properties={\"quality\": \"silver\"})\n",
    "# def si_devices_dimension():\n",
    "#     raw_data = dlt.read(\"br_fraud_detection_raw_data_historical\")\n",
    "#     return raw_data.groupBy(\"DeviceID\").agg(\n",
    "#         first(\"DeviceType\").alias(\"DeviceType\"),\n",
    "#         first(\"IP_Address\").alias(\"IP_Address\")\n",
    "#     )\n",
    "\n",
    "\n",
    "\n",
    "# # import dlt\n",
    "# # from pyspark.sql.functions import year, month, dayofweek, weekofyear, quarter, dayofweek, when\n",
    "\n",
    "# # @dlt.table(name=\"si_transaction_date_dimension\", comment=\"Silver quality Transaction Date Dimension table\", table_properties={\"quality\": \"silver\"})\n",
    "# # def si_transaction_date_dimension():\n",
    "# #     raw_data = dlt.read(\"br_fraud_detection_raw_data_historical\").filter(\"TransactionDate IS NOT NULL\")\n",
    "# #     return raw_data.selectExpr(\n",
    "# #         \"DISTINCT TransactionDate AS date_key\",\n",
    "# #         \"year(TransactionDate) AS year\",\n",
    "# #         \"month(TransactionDate) AS month\",\n",
    "# #         \"day(TransactionDate) AS day\",\n",
    "# #         \"weekofyear(TransactionDate) AS week\",\n",
    "# #         \"quarter(TransactionDate) AS quarter\",\n",
    "# #         when(dayofweek(\"TransactionDate\") == 1, 'Sunday')\n",
    "# #         .when(dayofweek(\"TransactionDate\") == 2, 'Monday')\n",
    "# #         .when(dayofweek(\"TransactionDate\") == 3, 'Tuesday')\n",
    "# #         .when(dayofweek(\"TransactionDate\") == 4, 'Wednesday')\n",
    "# #         .when(dayofweek(\"TransactionDate\") == 5, 'Thursday')\n",
    "# #         .when(dayofweek(\"TransactionDate\") == 6, 'Friday')\n",
    "# #         .otherwise('Saturday').alias(\"day_of_week\"),\n",
    "# #         when(month(\"TransactionDate\") == 1, 'January')\n",
    "# #         .when(month(\"TransactionDate\") == 2, 'February')\n",
    "# #         .when(month(\"TransactionDate\") == 3, 'March')\n",
    "# #         .when(month(\"TransactionDate\") == 4, 'April')\n",
    "# #         .when(month(\"TransactionDate\") == 5, 'May')\n",
    "# #         .when(month(\"TransactionDate\") == 6, 'June')\n",
    "# #         .when(month(\"TransactionDate\") == 7, 'July')\n",
    "# #         .when(month(\"TransactionDate\") == 8, 'August')\n",
    "# #         .when(month(\"TransactionDate\") == 9, 'September')\n",
    "# #         .when(month(\"TransactionDate\") == 10, 'October')\n",
    "# #         .when(month(\"TransactionDate\") == 11, 'November')\n",
    "# #         .otherwise('December').alias(\"month_name\")\n",
    "# #     )\n",
    "\n",
    "\n",
    "# # import dlt\n",
    "# # from pyspark.sql.functions import sum, count\n",
    "\n",
    "# # @dlt.table(name=\"go_transaction_trends\", comment=\"Gold quality Transaction Trends Analysis table\", table_properties={\"quality\": \"gold\"})\n",
    "# # def go_transaction_trends():\n",
    "# #     transactions_fact = dlt.read(\"si_transactions_fact\")\n",
    "# #     transaction_date_dimension = dlt.read(\"si_transaction_date_dimension\")\n",
    "# #     return transactions_fact.join(transaction_date_dimension, transactions_fact.TransactionDate == transaction_date_dimension.date_key) \\\n",
    "# #         .groupBy(\"date_key\", \"year\", \"month\", \"TransactionType\", \"IsFraud\") \\\n",
    "# #         .agg(\n",
    "# #             sum(\"TransactionAmount\").alias(\"total_transaction_amount\"),\n",
    "# #             count(\"TransactionID\").alias(\"total_transactions\"),\n",
    "# #             sum(when(transactions_fact.IsFraud == 1, transactions_fact.TransactionAmount).otherwise(0)).alias(\"fraudulent_amount\"),\n",
    "# #             count(when(transactions_fact.IsFraud == 1, transactions_fact.TransactionID)).alias(\"fraudulent_transactions\")\n",
    "# #         )\n",
    "\n",
    "\n",
    "\n",
    "# # Create or Refresh Gold quality table for user behavior metrics\n",
    "# @dlt.table(\n",
    "#   name=\"go_user_behavior_metrics\",\n",
    "#   comment=\"Gold quality table for user behavior metrics\",\n",
    "#   table_properties={\"quality\": \"gold\"\n",
    "#   }\n",
    "# )\n",
    "# def go_user_behavior_metrics():\n",
    "#     return (\n",
    "#         dlt.read(\"si_transactions_fact\")\n",
    "#         .groupBy(\"UserID\")\n",
    "#         .agg(\n",
    "#             F.count(\"TransactionID\").alias(\"total_transactions\"),\n",
    "#             F.avg(\"TransactionAmount\").alias(\"avg_transaction_amount\"),\n",
    "#             F.count(F.when(F.col(\"IsFraud\") == 1, \"TransactionID\")).alias(\"total_fraud_transactions\"),\n",
    "#             F.countDistinct(\"DeviceID\").alias(\"unique_devices\"),\n",
    "#             F.max(\"TransactionDate\").alias(\"last_transaction_date\"),\n",
    "#             F.min(\"TransactionDate\").alias(\"first_transaction_date\")\n",
    "#         )\n",
    "#     )\n",
    "\n",
    "\n",
    "\n",
    "# # Create or Refresh Gold quality table for merchant risk assessment\n",
    "# @dlt.table(\n",
    "#   name=\"go_merchant_risk_assessment\",\n",
    "#   comment=\"Gold quality table for merchant risk assessment\",\n",
    "#   table_properties={\"quality\": \"gold\"\n",
    "#   }\n",
    "# )\n",
    "# def go_merchant_risk_assessment():\n",
    "#     return (\n",
    "#         dlt.read(\"si_transactions_fact\")\n",
    "#         .groupBy(\"MerchantID\")\n",
    "#         .agg(\n",
    "#             F.count(\"TransactionID\").alias(\"total_transactions\"),\n",
    "#             F.count(F.when(F.col(\"IsFraud\") == 1, \"TransactionID\")).alias(\"total_fraud_transactions\"),\n",
    "#             F.sum(F.when(F.col(\"IsFraud\") == 1, F.col(\"TransactionAmount\")).otherwise(0)).alias(\"total_fraudulent_amount\"),\n",
    "#             F.avg(\"AnomalyScore\").alias(\"avg_anomaly_score\"),\n",
    "#             F.countDistinct(\"UserID\").alias(\"unique_users\")\n",
    "#         )\n",
    "#     )\n",
    "\n",
    "\n",
    "\n",
    "# # Create or Refresh Gold quality table for real-time fraud detection\n",
    "# @dlt.table(\n",
    "#   name=\"go_real_time_fraud_detection\",\n",
    "#   comment=\"Gold quality table for real-time fraud detection\",\n",
    "#   table_properties={\"quality\": \"gold\"\n",
    "#   }\n",
    "# )\n",
    "# def go_real_time_fraud_detection():\n",
    "#     return (\n",
    "#         dlt.read(\"si_transactions_fact\")\n",
    "#         .filter((F.col(\"AnomalyScore\") > 0.5) | (F.col(\"IsFraud\") == 1))\n",
    "#         .select(\n",
    "#             \"TransactionID\",\n",
    "#             \"TransactionDate\",\n",
    "#             \"TransactionAmount\",\n",
    "#             \"TransactionType\",\n",
    "#             \"UserID\",\n",
    "#             \"MerchantID\",\n",
    "#             \"DeviceID\",\n",
    "#             \"IP_Address\",\n",
    "#             \"AnomalyScore\",\n",
    "#             \"IsFraud\",\n",
    "#             F.when(F.col(\"AnomalyScore\") > 0.8, \"High Risk\")\n",
    "#              .when(F.col(\"AnomalyScore\") > 0.5, \"Moderate Risk\")\n",
    "#              .otherwise(\"Low Risk\").alias(\"fraud_risk_level\")\n",
    "#         )\n",
    "#     )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Create or Refresh Gold quality table for predictive model features\n",
    "# @dlt.table(\n",
    "#   name=\"go_predictive_model_features\",\n",
    "#   comment=\"Gold quality table for predictive model features\",\n",
    "#   table_properties={\"quality\": \"gold\"\n",
    "#   }\n",
    "# )\n",
    "# def go_predictive_model_features():\n",
    "#     # Reading the fact table and metrics from user behavior and merchant risk assessment\n",
    "#     transactions_fact = dlt.read(\"si_transactions_fact\")\n",
    "#     user_behavior_metrics = dlt.read(\"go_user_behavior_metrics\")\n",
    "#     merchant_risk_assessment = dlt.read(\"go_merchant_risk_assessment\")\n",
    "    \n",
    "#     # Joining tables to include user and merchant metrics for predictive features\n",
    "#     return (\n",
    "#         transactions_fact\n",
    "#         .join(user_behavior_metrics, transactions_fact.UserID == user_behavior_metrics.UserID, \"inner\")\n",
    "#         .join(merchant_risk_assessment, transactions_fact.MerchantID == merchant_risk_assessment.MerchantID, \"inner\")\n",
    "#         .select(\n",
    "#             transactions_fact.TransactionID,\n",
    "#             transactions_fact.TransactionAmount,\n",
    "#             transactions_fact.TransactionType,\n",
    "#             transactions_fact.AnomalyScore,\n",
    "#             user_behavior_metrics.total_transactions.alias(\"user_total_transactions\"),\n",
    "#             user_behavior_metrics.avg_transaction_amount.alias(\"user_avg_transaction_amount\"),\n",
    "#             user_behavior_metrics.total_fraud_transactions.alias(\"user_fraud_transactions\"),\n",
    "#             merchant_risk_assessment.total_fraud_transactions.alias(\"merchant_fraud_transactions\"),\n",
    "#             merchant_risk_assessment.avg_anomaly_score.alias(\"merchant_avg_anomaly_score\"),\n",
    "#             transactions_fact.IsFraud\n",
    "#         )\n",
    "#     )\n",
    "\n",
    "\n",
    "# # Create or Refresh Gold quality table for reporting and dashboarding\n",
    "# @dlt.table(\n",
    "#   name=\"go_fraud_detection_dashboard_metrics\",\n",
    "#   comment=\"Gold quality table for reporting and dashboarding metrics\",\n",
    "#   table_properties={\"quality\": \"gold\"\n",
    "#   }\n",
    "# )\n",
    "# def go_fraud_detection_dashboard_metrics():\n",
    "#     # Reading the transactions fact table\n",
    "#     transactions_fact = dlt.read(\"si_transactions_fact\")\n",
    "    \n",
    "#     # Aggregating the required metrics for fraud detection dashboarding\n",
    "#     return (\n",
    "#         transactions_fact\n",
    "#         .agg(\n",
    "#             F.count(\"TransactionID\").alias(\"total_transactions\"),\n",
    "#             F.sum(F.when(transactions_fact.IsFraud == 1, 1).otherwise(0)).alias(\"total_fraud_transactions\"),\n",
    "#             F.sum(F.when(transactions_fact.IsFraud == 1, transactions_fact.TransactionAmount).otherwise(0)).alias(\"total_fraudulent_amount\"),\n",
    "#             F.countDistinct(\"UserID\").alias(\"unique_users\"),\n",
    "#             F.countDistinct(\"MerchantID\").alias(\"unique_merchants\"),\n",
    "#             F.avg(\"AnomalyScore\").alias(\"avg_anomaly_score\"),\n",
    "#             F.max(\"TransactionDate\").alias(\"last_transaction_date\")\n",
    "#         )\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0a7f9089-b29c-4890-b7ef-70375a98e75f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_project.fraud_detection_data_python import *\n",
    "\n",
    "\n",
    "# from my_project import fraud_detection_data_python\n",
    "\n",
    "# fraud_detection_data_python.br_fraud_detection_raw_data_historical()\n",
    "# fraud_detection_data_python.si_transactions_fact()\n",
    "# fraud_detection_data_python.si_users_dimension()\n",
    "# fraud_detection_data_python.si_devices_dimension()\n",
    "# fraud_detection_data_python.go_user_behavior_metrics()\n",
    "# fraud_detection_data_python.go_merchant_risk_assessment()\n",
    "# fraud_detection_data_python.go_real_time_fraud_detection()\n",
    "# fraud_detection_data_python.go_predictive_model_features()\n",
    "# # Load Gold fraud detection dashboard metrics \n",
    "# fraud_detection_data_python.go_fraud_detection_dashboard_metrics()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "fraud-detection-data-python",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
